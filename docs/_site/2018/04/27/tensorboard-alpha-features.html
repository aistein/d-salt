<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.5.0 -->
<title>Tensorboard Alpha Features | D-SALT</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="Tensorboard Alpha Features" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Tensorboard is a the standard tool for visualizing deep neural networks. While we were all busy visualizing loss curves, Tensorboard released an interactive debugger." />
<meta property="og:description" content="Tensorboard is a the standard tool for visualizing deep neural networks. While we were all busy visualizing loss curves, Tensorboard released an interactive debugger." />
<link rel="canonical" href="http://localhost:4000/2018/04/27/tensorboard-alpha-features.html" />
<meta property="og:url" content="http://localhost:4000/2018/04/27/tensorboard-alpha-features.html" />
<meta property="og:site_name" content="D-SALT" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2018-04-27T00:00:00-04:00" />
<script type="application/ld+json">
{"description":"Tensorboard is a the standard tool for visualizing deep neural networks. While we were all busy visualizing loss curves, Tensorboard released an interactive debugger.","@type":"BlogPosting","url":"http://localhost:4000/2018/04/27/tensorboard-alpha-features.html","headline":"Tensorboard Alpha Features","dateModified":"2018-04-27T00:00:00-04:00","datePublished":"2018-04-27T00:00:00-04:00","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/2018/04/27/tensorboard-alpha-features.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/main.css"><link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="D-SALT" /></head>
<body><header class="site-header" role="banner">

  <div class="wrapper"><a class="site-title" rel="author" href="/">D-SALT</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/about/">About</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Tensorboard Alpha Features</h1>
    <p class="post-meta">
      <time class="dt-published" datetime="2018-04-27T00:00:00-04:00" itemprop="datePublished">Apr 27, 2018
      </time></p>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <p>As many of us know, Tensorboard is the leading tool for visualizing deep neural networks. It provides everything from graphing losses and histograms of weight values to 3D embedding maps of images, or words. Additionally, some Tensorflow users are familiar with the Tensorflow debugger, tfdbg.</p>

<h2 id="why-do-we-need-a-debugger">Why Do We Need A Debugger</h2>

<p>The first question to ask is why does Tensorflow need its own debugger at all?</p>

<p>For those of us less familiar with Tensorflow, you may have noticed a general code flow when building models in Tensorflow. First we define some computation as a series of nodes using declarations like <code class="highlighter-rouge">tf.layers.conv1d(...)</code>, then we pass data into those computations using a session <code class="highlighter-rouge">op = tf.Session().run([training_operation], feed_dict={x: 123})</code> (we’ll use a <code class="highlighter-rouge">feed_dict</code> here, but please read our post on Data Ingestion to find out about other options). So what is the output of this intermediary 1d convolution we’ve defined? In order to actually view the output we have to add the operation to our session run like this <code class="highlighter-rouge">op, conv = tf.Session().run([training_operation, conv], feed_dict={x: 123})</code>. What if we had a 100 layers and wanted to see the output at various layers? It gets immediately obvious that this solution does not scale.</p>

<p>So instead, what if you use the python debugger to step through your code? As we saw in another post (Data Ingestion), the python profiler shows the training of our network as a single python operation!</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   Ordered by: internal time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      851   24.341    0.029   24.341    0.029 {built-in method _pywrap_tensorflow_internal.TF_Run}
</code></pre></div></div>
<p>This wouldn’t be particularly useful to step through in a debugger.</p>

<p>Because tensorflow computational graphs are so difficult to debug, the Tensorflow team created tfdbg to allow users to step through graph computations and view intermediary values.</p>

<h2 id="using-the-command-line-debugger">Using The Command Line Debugger</h2>

<p>Activating and using Tensorflows command-line debugger is very simple.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">tensorflow.python</span> <span class="kn">import</span> <span class="n">debug</span> <span class="k">as</span> <span class="n">tf_debug</span>

<span class="n">sess</span> <span class="o">=</span> <span class="n">tf_debug</span><span class="o">.</span><span class="n">LocalCLIDebugWrapperSession</span><span class="p">(</span><span class="n">sess</span><span class="p">)</span>
</code></pre></div></div>

<p>We can then continue to use our session as usual to run a computational graph, but this time, we run our model with the the <code class="highlighter-rouge">--debug</code> flag passed to python.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">python</span> <span class="n">DeepCoNN</span>\ <span class="o">-</span>\ <span class="n">feed</span>\ <span class="nb">dict</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">debug</span>
</code></pre></div></div>
<p>From here we get to a view with some instructions on how to start running our computational graph</p>

<p><img src="/dlprof/assets/tfdbg_home.png" alt="tfdbg home" /></p>

<p>This screen gives us some simple instructions like <code class="highlighter-rouge">run</code> to start our computation. After typing run and hitting enter, we can step through our computational graph and view the outputs of different operations!</p>

<p><img src="/dlprof/assets/step_through_computations.png" alt="computation step" /></p>

<p>The Tensorflow debugger is an extremely useful tool, especially for finding out where and when gradients are becoming nan or zero, but in our particular case we need more context than what is provided above. To be specific, because our computational graph has two parallel word embedding lookups, one for user reviews and one for item reviews, the above image is not useful because we do not know which of the two is creating this gradient.</p>

<h2 id="a-more-friendly-debugger">A More Friendly Debugger</h2>

<p>To ease the use of the Tensorflow debugger, the team also created a visual debugging tool that takes advantage of Tensorboard! Unfortunately, this tool is in a alpha stage and has no official documentation on tensorflow.org outside of a link pointing to a README.</p>

<blockquote>
  <p>Q: Is there a GUI for tfdbg?</p>

  <p>A: Yes, the TensorBoard Debugger Plugin is the GUI of tfdbg. It offers features such as inspection of the computation graph, real-time visualization of tensor values, continuation to tensor and conditional breakpoints, and tying tensors to their graph-construction source code, all in the browser environment. To get started, please visit its <a href="https://github.com/tensorflow/tensorboard/blob/master/tensorboard/plugins/debugger/README.md">README</a>.</p>
</blockquote>

<p>We must, however, thank the Tensorflow team, because the included README is thorough. In order to run the visual Tensorflow debugger with a tf.Estimator we simply add the following hook to our train method.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">tensorflow.python</span> <span class="kn">import</span> <span class="n">debug</span> <span class="k">as</span> <span class="n">tf_debug</span>
<span class="n">hook</span> <span class="o">=</span> <span class="n">tf_debug</span><span class="o">.</span><span class="n">TensorBoardDebugHook</span><span class="p">(</span><span class="s">"localhost:6060"</span><span class="p">)</span>
<span class="n">s</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">scoring_function</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">input_fn</span><span class="o">=</span><span class="n">train_input_fn</span> <span class="p">,</span> <span class="n">hooks</span><span class="o">=</span><span class="p">[</span><span class="n">hook</span><span class="p">])</span>
</code></pre></div></div>
<p>From here we have to</p>
<ol>
  <li>Start tensorboard with the debugger flag listening on the port specified above</li>
  <li>Start training our model</li>
</ol>

<p>Note that it must be done in this order and we must provide tensorboard with the <code class="highlighter-rouge">--debugger_port</code> flag.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tensorboard <span class="nt">--logdir</span><span class="o">=</span>output <span class="nt">--debugger_port</span> 6060
</code></pre></div></div>

<p>Your tensorboard should now display a <code class="highlighter-rouge">Debugger</code> tab in addition to some of the standard tabs. Clicking on said tab gives us the following handy prompt in case you forgot to add the debugger hook.</p>

<p><img src="/dlprof/assets/handy_prompt.png" alt="handy prompt" /></p>

<p>If everything is set up and communicating correctly, then when you run your visual debugger enabled model your execution should pause and display some obscure message like <code class="highlighter-rouge">56 ops no flops stats due to incomplete shapes</code>. Unclear what this means, but I have taken it as a symbol that the debugger has stopped our model execution and is waiting for us to provide a command.</p>

<p><img src="/dlprof/assets/model_pause.png" alt="waiting for command" /></p>

<p>Looking back at tensorboard and the visual debugger now, we already have much more context than the command line tools. We can clearly see all our computational graph operations and tensors as well as which device those operations take place on.</p>

<p><img src="/dlprof/assets/operations_and_devices.png" alt="ops and devices" /></p>

<p>From here we can select a specific computation or variable, then monitor that computation through graph execution. For the purposes of this example I will select a convolution operation.</p>

<p><img src="/dlprof/assets/conv_operation_selection.png" alt="hash lookup selection" /></p>

<p>Now we can tell Tensorboard to continue running the debugger until some specific break conditions are met. For example we can run our model over 5 different sessions waiting until one of our selected tensors meets one of the provided conditions. This is menu and set of options is reached by clicking the <code class="highlighter-rouge">Continue</code> button in the bottom left. For purposes of the demonstration we will wait for some condition that is almost guaranteed to be true, like waiting for the max value of any of our watched tensors to be greater than -1. This condition should be just about guaranteed true because of our random initialization.</p>

<p><img src="/dlprof/assets/step_through.png" alt="step and continue buttons" /></p>

<p><img src="/dlprof/assets/run_till_break.png" alt="run till condition" /></p>

<p>After one of the conditions are met we get some very useful data on our selected operation and can even montor the value of our tensors. By hitting the continue button we can also watch the debugger loop through an iteration until it returns to the currently monitored tensor.</p>

<p><img src="/dlprof/assets/loop_through_iteration.gif" alt="loop" /></p>

<p>Although Tensorflow debugging can often be unruly the Tensorflow team and community have put a significant amount of time into developing tools that give us insight into their graph computation. Currently the visual debugger is only in an alpha release, but I could easily see a future where connecting the visual debugger is automatic. The visual debugger in particular could be an extremely useful tool for understanding how neural networks learn, or demonstrating things like networks that do not converge due to high learning rates. Even as an alpha release I see use for the visual debugger to understand how tensorflow models execute and why they either fail or work well. I am looking forward to seeing where the Tensorflow team takes this feature set in the future.</p>

  </div><a class="u-url" href="/2018/04/27/tensorboard-alpha-features.html" hidden></a>
</article>

      </div>
    </main>
<footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">D-SALT</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">D-SALT</li>
            <li><a class="u-email" href="mailto:as5281@columbia.edu">as5281@columbia.edu</a></li>
            <li><a class="u-email" href="mailto:kvm2116@columbia.edu">kvm2116@columbia.edu</a></li>
            <li><a class="u-email" href="mailto:pck2119@columbia.edu">pck2119@columbia.edu</a></li>
        </ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"><li><a href="https://github.com/aistein"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg> <span class="username">aistein</span></a></li>
</ul>
</div>

      <div class="footer-col footer-col-3">
        <p>D-SALT: Datacenter Sender Adaptive Low-Latency Transport</p>
      </div>
    </div>

  </div>

</footer>
</body>

</html>
